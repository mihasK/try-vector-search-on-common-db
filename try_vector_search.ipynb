{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# Cosine distance is the simplest operation!\n",
    "\n",
    "%%writefile utils/cosine_dist.py\n",
    "import numpy as np\n",
    "\n",
    "def cos_dist(e1,e2):\n",
    "    return 1 - np.dot(e1,e2) / np.sqrt(np.dot(e1,e1) * np.dot(e2, e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.cosine_dist import cos_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 1228.8 MB will be stored in a table\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_LEN = 1536  # Openai size\n",
    "\n",
    "NUM_DOCS = 2*10**5\n",
    "\n",
    "print(f'More than {4*NUM_DOCS*EMBEDDINGS_LEN / 10**6} MB will be stored in a table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import create_engine, insert, select, text, Integer, String, Text\n",
    "from sqlalchemy.orm import declarative_base, mapped_column, Session\n",
    "\n",
    "engine = create_engine('postgresql+psycopg://postgres:mysecretpassword@localhost:2345/postgres')\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text('CREATE EXTENSION IF NOT EXISTS vector'))\n",
    "    conn.commit()\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class Document(Base):\n",
    "    __tablename__ = 'document'\n",
    "    \n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    content = mapped_column(Text)\n",
    "    embedding = mapped_column(Vector(EMBEDDINGS_LEN))\n",
    "\n",
    "\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)\n",
    "session = Session(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.0,)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    session.execute(text(\"SELECT reltuples AS estimate FROM pg_class WHERE relname = 'document'\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    session.execute(text(\"SELECT count(*) from document\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will insert in batches\n",
    "BATCH_SIZE =  10**3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1536)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "centers = np.random.rand(NUM_DOCS//BATCH_SIZE,  EMBEDDINGS_LEN, )  \n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1536)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = np.random.randn(BATCH_SIZE, EMBEDDINGS_LEN) / 20\n",
    "error.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import njit\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# @njit(parallel=True)\n",
    "# def gen_random():\n",
    "#     return np.random.rand(num_docs, EMBEDDINGS_LEN)\n",
    "\n",
    "# generated_embeddings = gen_random()\n",
    "# generated_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write docs to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee19cdbcdbee432c8d039db3d117e282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "\n",
    "for i in trange(centers.shape[0]):\n",
    "    \n",
    "    embeddings = (centers[i] + error).tolist()  # batch_size x EMBEDDINGS_LEN\n",
    "    # print(embeddings.shape)\n",
    "    \n",
    "    # idx = np.arange(i*BATCH_SIZE, (i+1)*BATCH_SIZE)\n",
    "    \n",
    "    idx = list(range(i*BATCH_SIZE, (i+1)*BATCH_SIZE ))\n",
    "    \n",
    "    params = (\n",
    "        dict(\n",
    "            id=idx[j],\n",
    "            content=f'some unique content', #{idx[j]}',\n",
    "            embedding=embeddings[j]\n",
    "        )\n",
    "        for j in range(BATCH_SIZE)\n",
    "    )\n",
    "    session.bulk_insert_mappings(Document, params)\n",
    "    \n",
    "    session.flush()\n",
    "session.commit()\n",
    "    \n",
    "    # session.add_all((\n",
    "    #     Document(id=i*BATCH_SIZE + j, content=f'some unique content #{i*BATCH_SIZE + j}', embedding=embeddings[j, :])\n",
    "    #     for j in range(BATCH_SIZE)\n",
    "    # ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(200000.0,)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    session.execute(text(\"SELECT reltuples AS estimate FROM pg_class WHERE relname = 'document'\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(200000,)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    session.execute(text(\"SELECT count(*) from document\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "9.58 ms ± 197 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "[192, 193, 194, 195, 196, 197, 198, 199, 200, 201]\n"
     ]
    }
   ],
   "source": [
    "# Baseline communication time  - retrieve by IDs\n",
    "\n",
    "x = random.randint(0, centers.shape[0])\n",
    "print(x)\n",
    "\n",
    "# session.scalars(select(Document).order_by(Document.embedding.cosine_distance(doc_X_embeddings)).limit(10))\n",
    "def retrieve_by_ids():\n",
    "    return session.query(Document).filter(Document.id.in_(range(x, x+10))).all()\n",
    "%timeit retrieve_by_ids()\n",
    "docs_found = retrieve_by_ids()\n",
    "print([\n",
    "    d.id\n",
    "    for d in docs_found\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search by cosine dist. (witbout index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(text('DROP INDEX IF EXISTS my_index'))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12 s ± 124 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "For center #58, the closest docs found:\n",
      "   ID     Dist.\n",
      "-----  --------\n",
      "58516  0.996619\n",
      "58877  0.996554\n",
      "58825  0.996549\n",
      "58206  0.996523\n",
      "58686  0.996501\n",
      "58852  0.996488\n",
      "58968  0.996488\n",
      "58887  0.996481\n",
      "58791  0.996472\n",
      "58699  0.996469\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# from utils.cosine_dist import cos_dist\n",
    "\n",
    "x = random.randint(0, centers.shape[0])\n",
    "doc_X_embeddings = centers[x]\n",
    "\n",
    "def search(doc_X_embeddings):\n",
    "    return session.scalars(select(Document).order_by(Document.embedding.cosine_distance(doc_X_embeddings)).limit(10))\n",
    "\n",
    "%timeit search(doc_X_embeddings)\n",
    "\n",
    "docs_found = search(doc_X_embeddings)\n",
    "print(f'For center #{x}, the closest docs found:')\n",
    "print(tabulate([\n",
    "    {'ID': d.id, 'Dist.': cos_dist(d.embedding, doc_X_embeddings)}\n",
    "    for d in docs_found\n",
    "], headers='keys'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sqlalchemy import Index\n",
    "index = Index('my_index', Document.embedding,\n",
    "    postgresql_using='ivfflat',\n",
    "    postgresql_with={'lists': 100},\n",
    "    postgresql_ops={'embedding': 'vector_cosine_ops'}\n",
    ")\n",
    "index.create(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04 s ± 14.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "For center #181, the closest docs found:\n",
      "    ID       Dist.\n",
      "------  ----------\n",
      "181516  0.0019814\n",
      "181825  0.00197517\n",
      "181206  0.00197166\n",
      "181877  0.00197745\n",
      "181686  0.00197224\n",
      "181125  0.00197476\n",
      "181968  0.00196963\n",
      "181887  0.00197558\n",
      "181561  0.0019677\n",
      "181699  0.00197679\n"
     ]
    }
   ],
   "source": [
    "%timeit search(doc_X_embeddings)\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "docs_found = search(doc_X_embeddings)\n",
    "print(f'For center #{x}, the closest docs found:')\n",
    "print(tabulate([\n",
    "    {'ID': d.id, 'Dist.': cos_dist(d.embedding, doc_X_embeddings)}\n",
    "    for d in docs_found\n",
    "], headers='keys'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector-db-analysis-dNSBEJLj-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
