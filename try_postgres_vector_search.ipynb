{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity is an extremely simple algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils/cosine_dist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/cosine_dist.py\n",
    "\n",
    "# Cosine distance is the simplest operation!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cos_dist(e1,e2):\n",
    "    return 1 - np.dot(e1,e2) / np.sqrt(np.dot(e1,e1) * np.dot(e2, e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.cosine_dist import cos_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Postgres (docker container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run -d  --cpus=1 --memory=2g --name pgvector-c -e POSTGRES_PASSWORD=mysecretpassword -p 2345:5432 postgres-with-pgvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 100,000\n",
      "More than  0.61 GB  (size of embeddings only) will be stored in the table\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_LEN = 1536  # Openai size\n",
    "\n",
    "NUM_DOCS = 10**5\n",
    "\n",
    "print(f'Number of documents: {NUM_DOCS:,}')\n",
    "print(f'More than {4*NUM_DOCS*EMBEDDINGS_LEN / 10**9: .2} GB  (size of embeddings only) will be stored in the table')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data as several clusters (each doc = cluster center + gaussian error )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. clusters: 100\n",
      "Cluster size: 1000\n"
     ]
    }
   ],
   "source": [
    "NUM_CLUSTERS =  10**2\n",
    "CLUSTER_SIZE = int(NUM_DOCS / NUM_CLUSTERS)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "centers = np.random.rand(NUM_CLUSTERS,  EMBEDDINGS_LEN).astype(np.float32)\n",
    "print('Num. clusters:', centers.shape[0])\n",
    "errors = np.random.randn(CLUSTER_SIZE, EMBEDDINGS_LEN).astype(np.float32) / 20\n",
    "print('Cluster size:', errors.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility function, example of usage:\n",
      "next batch: (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
      "next batch: (10, 11, 12, 13, 14, 15, 16, 17, 18, 19)\n",
      "next batch: (20, 21, 22, 23, 24, 25, 26, 27, 28, 29)\n",
      "next batch: (30, 31, 32, 33, 34, 35, 36, 37, 38, 39)\n",
      "next batch: (40, 41, 42, 43, 44, 45, 46, 47, 48, 49)\n",
      "next batch: (50, 51, 52, 53, 54, 55, 56, 57, 58, 59)\n",
      "next batch: (60, 61, 62, 63, 64, 65, 66, 67, 68, 69)\n",
      "next batch: (70, 71, 72, 73, 74, 75, 76, 77, 78, 79)\n",
      "next batch: (80, 81, 82, 83, 84, 85, 86, 87, 88, 89)\n",
      "next batch: (90, 91, 92, 93, 94)\n"
     ]
    }
   ],
   "source": [
    "from utils.batched import batched\n",
    "print('Utility function, example of usage:')\n",
    "for b in batched(range(95), batch_size=10): print('next batch:', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for iterating over all docs:\n",
      "CPU times: user 56.7 ms, sys: 36.9 ms, total: 93.6 ms\n",
      "Wall time: 93.5 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def gen_data():\n",
    "    for i in range(NUM_CLUSTERS):\n",
    "        embeddings = (centers[i] + errors)#.tolist()\n",
    "        # idx = np.arange(i*CLUSTER_SIZE, (i+1)*CLUSTER_SIZE).astype(int)\n",
    "        idx = list(range(i*CLUSTER_SIZE, (i+1)*CLUSTER_SIZE ))\n",
    "\n",
    "\n",
    "        for j in range(CLUSTER_SIZE):\n",
    "            yield dict(\n",
    "                id=idx[j],\n",
    "                content=f'some unique content #{idx[j]}',\n",
    "                embedding=embeddings[j]\n",
    "            )\n",
    "\n",
    "print('Time for iterating over all docs:')\n",
    "%time for _ in gen_data(): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Re)Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import create_engine, insert, select, text, Integer, String, Text\n",
    "from sqlalchemy.orm import declarative_base, mapped_column, Session\n",
    "\n",
    "engine = create_engine('postgresql+psycopg://postgres:mysecretpassword@localhost:2345/postgres')\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text('CREATE EXTENSION IF NOT EXISTS vector'))\n",
    "    conn.commit()\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class Document(Base):\n",
    "    __tablename__ = 'document'\n",
    "    \n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    content = mapped_column(Text)\n",
    "    embedding = mapped_column(Vector(EMBEDDINGS_LEN))\n",
    "\n",
    "\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,)]\n"
     ]
    }
   ],
   "source": [
    "def count_currently():\n",
    "    print(list(\n",
    "        session.execute(text(\"SELECT count(*) from document\"))\n",
    "    ))\n",
    "count_currently()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Iterable\n",
    "# conn = engine.raw_connection()\n",
    "\n",
    "def insert_via_copy(conn, table_name, records: Iterable[dict], columns: Iterable=[], commit=True):\n",
    "    if not columns:\n",
    "        records = list(records)\n",
    "        columns = list(records[0].keys())\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            with cursor.copy(f\"COPY {table_name} ({', '.join(columns)}) FROM STDIN\") as copy:\n",
    "                for record in records:\n",
    "                    copy.write_row(tuple(record.values()))\n",
    "\n",
    "        if commit:\n",
    "            # print('comitting')\n",
    "            conn.commit()\n",
    "\n",
    "    except:\n",
    "        conn.rollback()\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write docs to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Write docs to db: 100%|██████████| 100000/100000 [00:28<00:00, 3519.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.02 s, sys: 644 ms, total: 6.66 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from utils.numpy_to_json import FastJSONEncoder\n",
    "import json \n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "limit = 1_000\n",
    "limit = None\n",
    "\n",
    "\n",
    "doc_list = islice(\n",
    "    gen_data(),\n",
    "    limit\n",
    ")\n",
    "\n",
    "conn = engine.raw_connection()\n",
    "\n",
    "for batch in batched(\n",
    "                  tqdm(\n",
    "                      doc_list,\n",
    "                      total=limit or NUM_DOCS,\n",
    "                      desc='Write docs to db'\n",
    "                    ),\n",
    "              batch_size):\n",
    "  \n",
    "    for doc in batch:\n",
    "      doc['embedding'] = json.dumps(doc['embedding'], cls=FastJSONEncoder)\n",
    "\n",
    "    insert_via_copy(conn, Document.__tablename__, \n",
    "                records=batch, \n",
    "                columns=('id', 'content', 'embedding'),\n",
    "                commit=False\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100000,)]\n"
     ]
    }
   ],
   "source": [
    "count_currently()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "3.05 ms ± 181 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96]\n"
     ]
    }
   ],
   "source": [
    "# Baseline communication time  - retrieve by IDs\n",
    "import random\n",
    "\n",
    "x = random.randint(0, centers.shape[0])\n",
    "print(x)\n",
    "\n",
    "# session.scalars(select(Document).order_by(Document.embedding.cosine_distance(doc_X_embeddings)).limit(10))\n",
    "def retrieve_by_ids():\n",
    "    return session.query(Document).filter(Document.id.in_(range(x, x+10))).all()\n",
    "%timeit retrieve_by_ids()\n",
    "docs_found = retrieve_by_ids()\n",
    "print([\n",
    "    d.id\n",
    "    for d in docs_found\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search by cosine dist. (witbout index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlalchemy.engine.cursor.CursorResult object at 0x137fce5f0>\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    session.execute(text('DROP INDEX IF EXISTS my_index'))\n",
    ")\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.19 ms ± 4.6 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n",
      "For center #57, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "57936  0.00327247\n",
      "57210  0.00336128\n",
      "57484  0.00336158\n",
      "57508  0.00336242\n",
      "57780  0.00336695\n",
      "57803  0.00337636\n",
      "57651  0.00337857\n",
      "57171  0.00338113\n",
      "57855  0.00338179\n",
      "57847  0.00338322\n",
      "3.87 ms ± 246 µs per loop (mean ± std. dev. of 7 runs, 3 loops each)\n",
      "For center #87, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "87936  0.0032472\n",
      "87484  0.00333744\n",
      "87210  0.00333887\n",
      "87780  0.00335813\n",
      "87508  0.00336373\n",
      "87171  0.00336623\n",
      "87847  0.00336719\n",
      "87855  0.00336879\n",
      "87882  0.00337005\n",
      "87576  0.00338191\n",
      "3.45 ms ± 340 µs per loop (mean ± std. dev. of 7 runs, 3 loops each)\n",
      "For center #99, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "99936  0.0032419\n",
      "99171  0.00335532\n",
      "99847  0.00335866\n",
      "99855  0.00336528\n",
      "99671  0.0033769\n",
      "99591  0.00337923\n",
      "99087  0.0033856\n",
      "99949  0.00338745\n",
      "99163  0.00338954\n",
      "99205  0.00340569\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tabulate import tabulate\n",
    "# from utils.cosine_dist import cos_dist\n",
    "\n",
    "\n",
    "def search(doc_X_embeddings, limit=10):\n",
    "    return session.scalars(select(Document).order_by(\n",
    "        Document.embedding.cosine_distance(doc_X_embeddings)).limit(limit)\n",
    "    )\n",
    "\n",
    "\n",
    "for _ in range(3):\n",
    "    x = random.randint(0, centers.shape[0]-1)\n",
    "    doc_X_embeddings = centers[x]\n",
    "        \n",
    "    %timeit -n 3 search(doc_X_embeddings)\n",
    "\n",
    "    docs_found = search(doc_X_embeddings)\n",
    "    print(f'For center #{x}, the closest docs found:')\n",
    "    print(tabulate([\n",
    "        {'ID': d.id, 'Dist.': cos_dist(d.embedding, doc_X_embeddings)}\n",
    "        for d in docs_found\n",
    "    ], headers='keys'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 ms, sys: 2.76 ms, total: 5.65 ms\n",
      "Wall time: 9.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sqlalchemy import Index\n",
    "\n",
    "def recreate_index(expected_number_of_clusters=10):\n",
    "\n",
    "    session.execute(text('DROP INDEX IF EXISTS my_index'))\n",
    "    session.commit()\n",
    "    index = Index('my_index', Document.embedding,\n",
    "        postgresql_using='ivfflat',\n",
    "        postgresql_with={'lists': expected_number_of_clusters},\n",
    "        postgresql_ops={'embedding': 'vector_cosine_ops'}\n",
    "    )\n",
    "    index.create(engine)\n",
    "\n",
    "recreate_index(expected_number_of_clusters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.04 ms ± 153 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "For a center #98, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "98780  0.0034411\n",
      "98814  0.00344491\n",
      "98882  0.00344986\n",
      "98847  0.00345266\n",
      "98163  0.00346398\n",
      "98499  0.00347525\n",
      "98507  0.00348258\n",
      "98305  0.00349295\n",
      "98385  0.00350589\n",
      "98174  0.0035128\n",
      "4.05 ms ± 355 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "For a center #54, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "54936  0.00330442\n",
      "54210  0.00338912\n",
      "54484  0.00340271\n",
      "54508  0.00340605\n",
      "54882  0.00341082\n",
      "54171  0.00341249\n",
      "54780  0.00341249\n",
      "54803  0.00342011\n",
      "54847  0.00342065\n",
      "54314  0.0034312\n",
      "110 ms ± 1.74 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "For a center #22, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "22936  0.00334799\n",
      "22210  0.00343323\n",
      "22484  0.00343531\n",
      "22780  0.00344211\n",
      "22171  0.00344431\n",
      "22847  0.00344867\n",
      "22508  0.00345004\n",
      "22576  0.0034557\n",
      "22803  0.00345761\n",
      "22882  0.00345981\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import random\n",
    "\n",
    "for _ in range(3):\n",
    "    x = random.randint(0, centers.shape[0]-1)\n",
    "    doc_X_embeddings = centers[x]\n",
    "    %timeit search(doc_X_embeddings)\n",
    "    docs_found = search(doc_X_embeddings)\n",
    "    print(f'For a center #{x}, the closest docs found:')\n",
    "    print(tabulate([\n",
    "        {'ID': d.id, 'Dist.': cos_dist(d.embedding, doc_X_embeddings)}\n",
    "        for d in docs_found\n",
    "    ], headers='keys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create index with wrong number of expected clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 ms, sys: 2.27 ms, total: 4.59 ms\n",
      "Wall time: 5.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 10 is less than real number of clusters, so search will be less effective\n",
    "# both in terms of time, and recall rate will decrease\n",
    "recreate_index(expected_number_of_clusters=10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with non-optimal index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 ms ± 2.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "For a center #52, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "52936  0.00331742\n",
      "52210  0.00339168\n",
      "52780  0.00339967\n",
      "52484  0.00340068\n",
      "52508  0.00341493\n",
      "52847  0.00341809\n",
      "52803  0.00342214\n",
      "52814  0.00342488\n",
      "52576  0.0034284\n",
      "52507  0.00343168\n",
      "181 ms ± 2.56 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "For a center #72, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "72936  0.00323367\n",
      "72803  0.00331903\n",
      "72484  0.00332761\n",
      "72210  0.00332987\n",
      "72780  0.00333238\n",
      "72847  0.00333828\n",
      "72508  0.00334734\n",
      "72576  0.00335163\n",
      "72882  0.00335211\n",
      "72814  0.00335699\n",
      "181 ms ± 2.97 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "For a center #53, the closest docs found:\n",
      "   ID       Dist.\n",
      "-----  ----------\n",
      "53936  0.00326687\n",
      "53210  0.00336123\n",
      "53484  0.0033676\n",
      "53780  0.00337124\n",
      "53508  0.0033744\n",
      "53882  0.00338584\n",
      "53847  0.00338614\n",
      "53576  0.00338781\n",
      "53171  0.00338817\n",
      "53803  0.00339353\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import random\n",
    "\n",
    "for _ in range(3):\n",
    "    x = random.randint(0, centers.shape[0]-1)\n",
    "    doc_X_embeddings = centers[x]\n",
    "    %timeit search(doc_X_embeddings)\n",
    "    docs_found = search(doc_X_embeddings)\n",
    "    print(f'For a center #{x}, the closest docs found:')\n",
    "    print(tabulate([\n",
    "        {'ID': d.id, 'Dist.': cos_dist(d.embedding, doc_X_embeddings)}\n",
    "        for d in docs_found\n",
    "    ], headers='keys'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
